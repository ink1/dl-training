{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#matplotlib.use(\"Agg\")\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if necessary, set CUDA_VISIBLE_DEVICES to -1 to use CPU\n",
    "# or to GPU ID (e.g. 0) to use GPU\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF backend assumes \"channels_last data shape layout\n",
    "# For 2D data \"channels_last\" means (rows, cols, channels)\n",
    "# while \"channels_first\" assumes (channels, rows, cols). \n",
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load CIFAR10 data\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape, testX.shape)\n",
    "print(trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the label names for the CIFAR-10 dataset\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "num_classes = len(labelNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "print(trainY[n,:])\n",
    "#print(labelNames[np.argmax(trainY[n,:])])\n",
    "print(labelNames[trainY[n,0]])\n",
    "plt.imshow(trainX[n,::], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalise data\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize labels in a one-vs-all fashion\n",
    "\n",
    "Several regression and binary classification algorithms are\n",
    "available in the scikit-learn. A simple way to extend these algorithms\n",
    "to the multi-class classification case is to use the so-called\n",
    "one-vs-all scheme.\n",
    "\n",
    "At learning time, this simply consists in learning one regressor\n",
    "or binary classifier per class. In doing so, one needs to convert\n",
    "multi-class labels to binary labels (belong or does not belong\n",
    "to the class). LabelBinarizer makes this process easy with the\n",
    "transform method.\n",
    "\n",
    "At prediction time, one assigns the class for which the corresponding\n",
    "model gave the greatest confidence. LabelBinarizer makes this easy\n",
    "with the inverse_transform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "# Fit label binarizer and transform multi-class labels to binary labels.\n",
    "# The output of transform is sometimes referred to as the 1-of-K coding scheme.\n",
    "\n",
    "# Why are we using fit_transform in one case and transform in the other\n",
    "# even though dimensions of are identical?\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively the same can be achieved using Keras rather than scikit-learn. \n",
    "Convert class vectors to binary class matrices using keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainY = keras.utils.to_categorical(trainY, num_classes)\n",
    "#testY = keras.utils.to_categorical(testY, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainY[0])\n",
    "print(testY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(width, height, depth, classes, dropout=False, batch_normalisation=False):\n",
    "\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    \n",
    "    # if we are using \"channels first\", update the input shape\n",
    "    # and channels dimension\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        print(\"adapt shape to channels_first\")\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "\n",
    "    # first CONV => RELU => BN => CONV => RELU => BN => POOL layer set\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    if batch_normalisation:\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    if batch_normalisation:\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "    # second CONV => RELU => BN => CONV => RELU => BN => POOL layer set\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    if batch_normalisation:\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    if batch_normalisation:\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "    # first (and only) set of FC => RELU => BN layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    if batch_normalisation:\n",
    "        model.add(BatchNormalization())\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "    # softmax classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    # return the constructed network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "\n",
    "model = build_model(width=32, height=32, depth=3, classes=10, dropout=False, batch_normalisation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the optimizer\n",
    "\n",
    "opt = SGD(lr=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True)\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network. On 1080 Ti it takes 4-5 sec per epoch, on fast CPU ~ 45 sec\n",
    "#                      w/o BN   with BN\n",
    "# batch_size   64- 128     4s\n",
    "# batch_size  256-1024     3s       5s\n",
    "\n",
    "nb_epoch = 30  # 40\n",
    "\n",
    "H = model.fit(trainX, trainY, \n",
    "              batch_size=64, \n",
    "              epochs=nb_epoch, \n",
    "              validation_data=(testX, testY),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model (with weights) and just weights\n",
    "# model can be later loaded with\n",
    "# keras.models.load_model(filename)\n",
    "# for weights to be loaded a model needs to be defined first\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "weights_name = 'keras_cifar10_trained_weights.h5'\n",
    "weights_path = os.path.join(save_dir, weights_name)\n",
    "model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "predictions = model.predict(testX, batch_size=64)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "    predictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Confusion matrix and its plot\n",
    "orig_testY=testY.argmax(axis=1)\n",
    "pred_testY=predictions.argmax(axis=1)\n",
    "cnf_matrix=confusion_matrix(orig_testY,pred_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.style.use(\"seaborn-white\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, nb_epoch), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, nb_epoch), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training and Validation Loss on CIFAR-10\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy\n",
    "plt.style.use(\"seaborn-white\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, nb_epoch), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, nb_epoch), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training and Validation Accuracy on CIFAR-10\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "# Computes the loss on some input data, batch by batch.\n",
    "scores = model.evaluate(testX, testY, batch_size=64, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the optimizer\n",
    "\n",
    "opt = SGD(lr=0.001, decay=0.01 / 40, momentum=0.9, nesterov=True)\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10  # 40\n",
    "\n",
    "H = model.fit(trainX, trainY, \n",
    "              batch_size=64, \n",
    "              epochs=nb_epoch, \n",
    "              validation_data=(testX, testY),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35k203]",
   "language": "python",
   "name": "conda-env-py35k203-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
