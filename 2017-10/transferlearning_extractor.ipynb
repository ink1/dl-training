{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with Imagenet\n",
    "\n",
    "Keras library provides off the shelf CNNs that have been pre-trained on the Imagenet dataset:\n",
    "VGG16, VGG19, ResNet50, Inception V3 and Xception.\n",
    "\n",
    "Today our focus is on using VGG16 network architecture. \n",
    "This architecture has been introduced by Simonyan and Zisserman in \n",
    "\"Very Deep Convolutional Networks for Large Scale Image Recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from vgg16 import VGG16\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "model = VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "#Visualize the break down of the model\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Visualize other parameters of the model like trainable,name of the layer etc...\n",
    "model.layers[-1].get_config()\n",
    "model.layers[-2].get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "img_path = '../dataTL/dogs/dog_.1_.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)\n",
    "\n",
    "plt.imshow(img)\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN as a feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "model.summary()\n",
    "model.layers[-1].get_config()\n",
    "\n",
    "img_path = '../dataTL/dogs/dog_.1_.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)\n",
    "\n",
    "features1=features.reshape(-1,25088)\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "print(features1.shape)\n",
    "\n",
    "print(features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras200]",
   "language": "python",
   "name": "conda-env-keras200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
