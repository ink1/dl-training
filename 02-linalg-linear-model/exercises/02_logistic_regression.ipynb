{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Wisconsin Breast Cancer dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) contains features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. After segmenting cell nuclei present in the image, ten nuclear features were calculated for each cell. These features are modeled such that higher values are typically associated with malignancy. The mean value, worst (mean of the three largest values), and standard error of each feature were computed for each image, resulting in a total of 30 features for each case in the study:\n",
    "\n",
    "1. radius (mean of distances from center to points on the perimeter)\n",
    "2. texture (standard deviation of gray-scale values)\n",
    "3. perimeter\n",
    "4. area\n",
    "5. smoothness (local variation in radius lengths)\n",
    "6. compactness (perimeter^2 / area - 1.0)\n",
    "7. concavity (severity of concave portions of the contour)\n",
    "8. concave points (number of concave portions of the contour)\n",
    "9. symmetry \n",
    "10. fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The objective is to determine how points can best be separated into *benign* and *malignant* sets in the case of diagnosis, and into *recurring* and *nonrecurring* sets in the case of prognosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Least Squares\n",
    "\n",
    "Weighted Least Squares (WLS) is an extension to least squares, where each sample\n",
    "is associated with a weight $w_i$. Accordingly, the weighted least squares estimate\n",
    "is defined as\n",
    "$$\n",
    "\\hat{\\beta} = \\left( \\mathbf{X}^\\top \\mathbf{W} \\mathbf{X} \\right)^{-1} \\mathbf{X}^\\top \\mathbf{W}^\\top \\mathbf{y} ,\n",
    "$$\n",
    "where $\\mathbf{W}$ is a diagonal matrix containing the weights ($W_{ii} = w_i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively Reweighted Least Squares (IRLS)\n",
    "\n",
    "The maximum likelihood estimate for logistic regression is defined as\n",
    "$$\n",
    "\\hat{\\beta} = \\arg \\max_{\\beta} \\sum_{i = 1}^n y_i \\log(\\pi_i) + (1 - y_i) \\log(1 - \\pi_i) ,\n",
    "$$\n",
    "where $\\pi_i$ denotes the probability $P(y_i = 1 \\mid \\mathbf{x}_i)$ defined as\n",
    "$$\n",
    " P(y_i = 1 \\mid \\mathbf{x}_i) = \\frac{\\exp \\left( \\beta_0 + \\sum_{j=1}^m \\beta_j x_{ij} \\right)}\n",
    "{1 + \\exp \\left( \\beta_0 + \\sum_{j=1}^m \\beta_j x_{ij} \\right)}.\n",
    "$$\n",
    "\n",
    "In comparison to least squares, there is no closed form solution to this problem,\n",
    "therefore one has to find estimates iteratively. A common approach is to\n",
    "iteratively compute a weighted least squares fit until converge, called\n",
    "**iteratively reweighted least squares** (IRLS).\n",
    "\n",
    "The weights $w_i$ of the diagonal matrix $\\mathbf{W}$ are defined as $w_i = \\pi_i (1 - \\pi_i)$ and\n",
    "the **working response** $\\mathbf{z} \\in \\mathbb{R}^n$ as\n",
    "$$\n",
    "\\mathbf{z} = \\mathbf{X} \\beta_\\text{old} +\\mathbf{W}^{-1} (\\mathbf{y} - \\mathbf{p}) ,\n",
    "$$\n",
    "where the vector $\\mathbf{p} \\in \\mathbb{R}^n$ contains the fitted probabilities\n",
    "$\\pi_i$. This leads to the following weighted least squares problem:\n",
    "$$\n",
    "\\beta_\\text{new} = \\left( \\mathbf{X}^\\top \\mathbf{W} \\mathbf{X} \\right)^{-1}\n",
    "  \\mathbf{X}^\\top \\mathbf{W} \\mathbf{z} ,\n",
    "$$\n",
    "where the right side of the equation is evaluated at $\\beta_\\text{old}$.\n",
    "\n",
    "These equations get solved repeatedly, since at each iteration the vector\n",
    "$\\mathbf{p}$ changes, and hence does $\\mathbf{W}$ and $\\mathbf{z}$.\n",
    "Typically, the convergence criteria is based on the **deviance** ($-2 \\cdot \\text{log-liklihood})$\n",
    "and is defined as\n",
    "$$\n",
    "  \\frac{\\lvert \\mathrm{deviance}({\\beta}_\\text{new}) - \\mathrm{deviance}({\\beta}_\\text{old}) \\rvert}\n",
    "  {\\lvert \\mathrm{deviance}({\\beta}_\\text{old}) \\rvert + 0.1} < 10^{-8}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_features():\n",
    "    names = ['radius', 'texture', 'perimeter', 'area', 'smoothness', 'compactness',\n",
    "             'concavity', 'concave points', 'symmetry', 'fractal dimension']\n",
    "\n",
    "    columns = [\"mean_{}\".format(v) for v in names]\n",
    "    columns.extend([\"se_{}\".format(v) for v in names])\n",
    "    columns.extend([\"worst_{}\".format(v) for v in names])\n",
    "    return columns\n",
    "\n",
    "\n",
    "def load_wisconsin_breast_cancer_diagnosis(local_file='../datasets/wdbc.data'):\n",
    "    columns = ['ID', 'diagnosis']\n",
    "    columns.extend(image_features())\n",
    "\n",
    "    data = pd.read_csv(Path(local_file), index_col=0, header=None,\n",
    "                       names=columns, dtype={'diagnosis': 'category'})\n",
    "    y = data.diagnosis.cat.rename_categories(['benign', 'malignant'])\n",
    "    X = data.drop('diagnosis', axis=1).astype(float)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_wisconsin_breast_cancer_prognosis(local_file='../datasets/wpbc.data'):\n",
    "    columns = ['ID', 'outcome', 'time']\n",
    "    outcomes = columns[1:]\n",
    "    extra_vars = ['tumor_size', 'lymph_node_status']\n",
    "    columns.extend(image_features())\n",
    "    columns.extend(extra_vars)\n",
    "\n",
    "    data = pd.read_csv(Path(local_file), index_col=0, header=None,\n",
    "                       names=columns, dtype={'outcome': 'category'},\n",
    "                       na_values=['?'])\n",
    "    y = data.loc[:, outcomes]\n",
    "    y.outcome.cat.rename_categories(['nonrecurring', 'recurring'], inplace=True)\n",
    "    X = data.drop(outcomes, axis=1).astype(float)\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Benign vs Malignant\n",
    "\n",
    "First, we want to classify individual cell nuclei as *benign* or *malignant* based on the 30 features derived from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diagnosis, y_diagnosis = load_wisconsin_breast_cancer_diagnosis()\n",
    "\n",
    "print(X_diagnosis.shape)\n",
    "print(y_diagnosis.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Recurrence\n",
    "\n",
    "Next, we want to create a model to predict *recurrence before 24 months* vs. *nonrecurrence beyond 24 months*. The data has two additional features:\n",
    "\n",
    "1. Tumor size (diameter of the excised tumor in centimeters)\n",
    "2. Lymph node status (number of positive axillary lymph nodes observed at time of surgery).\n",
    "\n",
    "**Note:** Lymph node status is missing in 4 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prognosis, y_prognosis = load_wisconsin_breast_cancer_prognosis()\n",
    "\n",
    "print(X_prognosis.shape)\n",
    "print(y_prognosis.outcome.value_counts())\n",
    "\n",
    "plt.hist([\n",
    "    y_prognosis.time[y_prognosis.outcome == 'recurring'],\n",
    "    y_prognosis.time[y_prognosis.outcome == 'nonrecurring'],\n",
    "], label=['recurring', 'nonrecurring'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
